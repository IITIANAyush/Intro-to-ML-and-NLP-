{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st part- generation of the dataset using templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_templates = [\n",
    "    \"This product is {adj1} and {adj2}.\",\n",
    "    \"Absolutely {adj1}! Highly recommend it.\",\n",
    "    \"Very {adj1} performance, I'm {adj2} with it.\",\n",
    "    \"A {adj1} purchase, truly {adj2}.\",\n",
    "    \"Works {adj1}! So {adj2}.\",\n",
    "    \"I'm {adj1} with the quality, it's very {adj2}.\",\n",
    "    \"Excellent value and {adj1} features.\",\n",
    "    \"The customer service was {adj1} and the item arrived {adj2}.\",\n",
    "    \"Simply {adj1}, exceeds expectations.\",\n",
    "    \"Totally {adj1}, would buy again.\"\n",
    "]\n",
    "\n",
    "bad_templates = [\n",
    "    \"This product is {adj1} and {adj2}.\",\n",
    "    \"Absolutely {adj1}! Do not recommend it.\",\n",
    "    \"Very {adj1} performance, I'm {adj2} with it.\",\n",
    "    \"A {adj1} purchase, truly {adj2}.\",\n",
    "    \"Doesn't work {adj1}! So {adj2}.\",\n",
    "    \"I'm {adj1} with the quality, it's very {adj2}.\",\n",
    "    \"Poor value and {adj1} features.\",\n",
    "    \"The customer service was {adj1} and the item arrived {adj2}.\",\n",
    "    \"Simply {adj1}, far below expectations.\",\n",
    "    \"Totally {adj1}, would not buy again.\"\n",
    "]\n",
    "\n",
    "good_adjectives = [\n",
    "    \"great\", \"excellent\", \"superb\", \"fantastic\", \"amazing\",\n",
    "    \"satisfied\", \"pleased\", \"happy\", \"reliable\", \"efficient\",\n",
    "    \"durable\", \"user-friendly\", \"top-notch\", \"smooth\", \"perfect\"\n",
    "]\n",
    "\n",
    "bad_adjectives = [\n",
    "    \"terrible\", \"horrible\", \"bad\", \"awful\", \"disappointing\",\n",
    "    \"frustrating\", \"broken\", \"unreliable\", \"slow\", \"complicated\",\n",
    "    \"cheap\", \"useless\", \"defective\", \"rough\", \"flawed\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthetic Product Feedback Dataset Created ---\n",
      "                                                text label\n",
      "0             Simply reliable, exceeds expectations.  good\n",
      "1                  Totally durable, would buy again.  good\n",
      "2              Simply pleased, exceeds expectations.  good\n",
      "3   I'm excellent with the quality, it's very great.  good\n",
      "4                A broken purchase, truly defective.   bad\n",
      "..                                               ...   ...\n",
      "95       Simply frustrating, far below expectations.   bad\n",
      "96             Excellent value and amazing features.  good\n",
      "97           Simply efficient, exceeds expectations.  good\n",
      "98                       Doesn't work awful! So bad.   bad\n",
      "99                      Works top-notch! So amazing.  good\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "good    50\n",
      "bad     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def generate_feedback(label_type):\n",
    "    \"\"\"Generates a single product feedback review based on label type.\"\"\"\n",
    "    if label_type == \"good\":\n",
    "        template = random.choice(good_templates)\n",
    "        adj1 = random.choice(good_adjectives)\n",
    "        adj2 = random.choice(good_adjectives)\n",
    "    else: # label_type == \"bad\"\n",
    "        template = random.choice(bad_templates)\n",
    "        adj1 = random.choice(bad_adjectives)\n",
    "        adj2 = random.choice(bad_adjectives)\n",
    "    return template.format(adj1=adj1, adj2=adj2)\n",
    "\n",
    "feedback_data = []\n",
    "# Generate 50 'good' feedback samples\n",
    "for _ in range(50):\n",
    "    feedback_data.append({\"text\": generate_feedback(\"good\"), \"label\": \"good\"})\n",
    "# Generate 50 'bad' feedback samples\n",
    "for _ in range(50):\n",
    "    feedback_data.append({\"text\": generate_feedback(\"bad\"), \"label\": \"bad\"})\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(feedback_data)\n",
    "df = pd.DataFrame(feedback_data)\n",
    "print(\"--- Synthetic Product Feedback Dataset Created ---\")\n",
    "print(df)\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorizing the dataset as per question i.e (300 max features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=300, lowercase=True, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd part :\n",
    "\n",
    "splitting the dataset into 75% training sample and 25% testing sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 rd Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression Model Training Complete ---\n",
      "Accuracy on the test set: 100.00%\n",
      "Precision (for 'good' label): 100.00%\n",
      "Recall (for 'good' label): 1.00\n",
      "F1-Score (for 'good' label): 1.00\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='good') # Specify 'good' as the positive class\n",
    "recall = recall_score(y_test, y_pred, pos_label='good')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='good')\n",
    "\n",
    "print(\"\\n--- Logistic Regression Model Training Complete ---\")\n",
    "print(f\"Accuracy on the test set: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision (for 'good' label): {precision*100:.2f}%\")\n",
    "print(f\"Recall (for 'good' label): {recall:.2f}\")\n",
    "print(f\"F1-Score (for 'good' label): {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th Part\n",
    "\n",
    "using set of manual example to check the acuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing the text_preprocess_vectorize function and prediction ---\n",
      "Text: 'This is an amazing product, I love it!' -> Predicted Label: good\n",
      "Text: 'The battery life is terrible and it's very slow.' -> Predicted Label: bad\n",
      "Text: 'It's okay, not great but not bad either.' -> Predicted Label: good\n",
      "Text: 'Wonderful customer support and fast delivery.' -> Predicted Label: good\n"
     ]
    }
   ],
   "source": [
    "def text_preprocess_vectorize(texts, fitted_vectorizer):\n",
    "    vectorized_matrix = fitted_vectorizer.transform(texts)\n",
    "    return vectorized_matrix\n",
    "\n",
    "print(\"\\n--- Testing the text_preprocess_vectorize function and prediction ---\")\n",
    "\n",
    "# Example texts to test the function\n",
    "new_texts = [\n",
    "    \"This is an amazing product, I love it!\",            # 'good'\n",
    "    \"The battery life is terrible and it's very slow.\", #  'bad'\n",
    "    \"It's okay, not great but not bad either.\",         # Ambiguous, model will predict based on learned patterns\n",
    "    \"Wonderful customer support and fast delivery.\"      #  'good'\n",
    "]\n",
    "\n",
    "new_texts_vectorized = text_preprocess_vectorize(new_texts, vectorizer)\n",
    "\n",
    "new_predictions = model.predict(new_texts_vectorized)\n",
    "\n",
    "for i, text in enumerate(new_texts):\n",
    "    print(f\"Text: '{text}' -> Predicted Label: {new_predictions[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
